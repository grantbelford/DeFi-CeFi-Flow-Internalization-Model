{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eb303b8-0704-4c29-831f-2a2f2794e0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/tfp9tldx3nq9004lhg26p4zc0000gn/T/ipykernel_95515/3549048568.py:89: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  orderbook_df = orderbook_df.groupby(['timestamp', 'type']).apply(\n",
      "/var/folders/81/tfp9tldx3nq9004lhg26p4zc0000gn/T/ipykernel_95515/3549048568.py:51: DeprecationWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if not pd.api.types.is_datetime64tz_dtype(df[col]):\n",
      "/var/folders/81/tfp9tldx3nq9004lhg26p4zc0000gn/T/ipykernel_95515/3549048568.py:51: DeprecationWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if not pd.api.types.is_datetime64tz_dtype(df[col]):\n",
      "/var/folders/81/tfp9tldx3nq9004lhg26p4zc0000gn/T/ipykernel_95515/3549048568.py:51: DeprecationWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if not pd.api.types.is_datetime64tz_dtype(df[col]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Data Verification ===\n",
      "Post-correction datetime types:\n",
      "1inch: datetime64[ns, UTC]\n",
      "OHLCV: datetime64[ns, UTC]\n",
      "Orderbook: datetime64[ns, UTC]\n",
      "\n",
      "1inch data sample:\n",
      "1inch head:\n",
      "                  block_time trade_type  sold_amount  bought_amount  \\\n",
      "0 2025-05-07 09:08:47+00:00  WETH_SELL     0.144511     265.918139   \n",
      "1 2025-05-07 09:08:23+00:00  WETH_SELL    21.539799   39654.090969   \n",
      "2 2025-05-07 09:07:59+00:00   WETH_BUY   250.000000       0.135428   \n",
      "\n",
      "   price_per_eth  \n",
      "0    1840.117926  \n",
      "1    1840.968498  \n",
      "2    1845.998845  \n",
      "1inch tail:\n",
      "                     block_time trade_type  sold_amount  bought_amount  \\\n",
      "1792 2025-05-05 08:11:23+00:00  WETH_SELL        0.060     109.496378   \n",
      "1793 2025-05-05 08:10:11+00:00   WETH_BUY       30.000       0.017653   \n",
      "1794 2025-05-05 08:04:23+00:00  WETH_SELL        0.027      49.488563   \n",
      "\n",
      "      price_per_eth  \n",
      "1792    1824.939633  \n",
      "1793    1699.441320  \n",
      "1794    1832.909741  \n",
      "\n",
      "Binance OHLCV head:\n",
      "                   timestamp     open     high      low    close    volume  \\\n",
      "0 2025-05-05 08:00:00+00:00  1826.58  1826.58  1825.48  1825.48  193.9876   \n",
      "0 2025-05-05 08:01:00+00:00  1827.07  1827.59  1827.07  1827.30   64.4692   \n",
      "0 2025-05-05 08:02:00+00:00  1826.60  1826.60  1826.40  1826.41    6.8143   \n",
      "\n",
      "                     minute  \n",
      "0 2025-05-05 08:00:00+00:00  \n",
      "0 2025-05-05 08:01:00+00:00  \n",
      "0 2025-05-05 08:02:00+00:00  \n",
      "\n",
      "Binance OHLCV tail:\n",
      "                   timestamp     open     high      low    close    volume  \\\n",
      "0 2025-05-07 09:58:00+00:00  1844.00  1844.07  1843.97  1843.97   45.2515   \n",
      "0 2025-05-07 09:59:00+00:00  1843.89  1844.27  1843.83  1844.27  275.0869   \n",
      "0 2025-05-07 10:00:00+00:00  1844.03  1844.92  1844.00  1844.00  410.4227   \n",
      "\n",
      "                     minute  \n",
      "0 2025-05-07 09:58:00+00:00  \n",
      "0 2025-05-07 09:59:00+00:00  \n",
      "0 2025-05-07 10:00:00+00:00  \n",
      "\n",
      "Binance Order book bids head:\n",
      "        price   amount                 timestamp  type  cum_amount  \\\n",
      "100  1825.47  18.0151 2025-05-05 08:00:00+00:00  bids     18.0151   \n",
      "101  1825.46   0.0145 2025-05-05 08:00:00+00:00  bids     18.0296   \n",
      "102  1825.45   0.0061 2025-05-05 08:00:00+00:00  bids     18.0357   \n",
      "\n",
      "                       minute  \n",
      "100 2025-05-05 08:00:00+00:00  \n",
      "101 2025-05-05 08:00:00+00:00  \n",
      "102 2025-05-05 08:00:00+00:00  \n",
      "\n",
      "Binance Order book bids tail:\n",
      "           price   amount                 timestamp  type  cum_amount  \\\n",
      "439997  1842.86  16.5041 2025-05-07 10:00:00+00:00  bids   1009.2767   \n",
      "439998  1842.85   3.7653 2025-05-07 10:00:00+00:00  bids   1013.0420   \n",
      "439999  1842.84   0.8426 2025-05-07 10:00:00+00:00  bids   1013.8846   \n",
      "\n",
      "                          minute  \n",
      "439997 2025-05-07 10:00:00+00:00  \n",
      "439998 2025-05-07 10:00:00+00:00  \n",
      "439999 2025-05-07 10:00:00+00:00  \n",
      "\n",
      "Data ranges:\n",
      "1inch range: 2025-05-05 08:04:23+00:00 to 2025-05-07 09:08:47+00:00\n",
      "Binance OHLCV range: 2025-05-05 08:00:00+00:00 to 2025-05-07 10:00:00+00:00\n",
      "\n",
      "Record counts:\n",
      "1inch trades: 1795\n",
      "Binance OHLCV: 2200\n",
      "Binance Order Book entries: 440000\n",
      "\n",
      "=== Trade Filtering Report ===\n",
      "Total trades: 1795\n",
      "Trades that will be skipped: 778\n",
      "\n",
      "SKIP REASONS:\n",
      "\n",
      "No Orderbook: 487\n",
      "First example - Time: 2025-05-05 09:49:47+00:00, Size: 0.0023 ETH\n",
      "\n",
      "Small Size: 291\n",
      "Last Example - Time: 2025-05-07 08:43:59+00:00, Size: 0.0094049017302119 ETH\n",
      "\n",
      "Time Alignment: 0\n",
      "\n",
      "Preprocessed .pkl data saved to 'processed_data' dir for Step2b & 2c\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step2a. Create DF\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# --- Config ---\n",
    "SMALL_TRADE_THRESHOLD = 0.01  # Min ETH trade size to process\n",
    "\n",
    "def load_binance_data(file_pattern, is_orderbook=False):\n",
    "    \"\"\"Load Binance data from CSV files with pattern matching\"\"\"\n",
    "    files = glob.glob(file_pattern)\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            # Extract timestamp from filename (format: ETHUSDT_yyyymmdd_hhmm_type.csv)\n",
    "            parts = os.path.basename(file).split('_')\n",
    "            timestamp_str = parts[1] + '_' + parts[2]\n",
    "            timestamp = datetime.strptime(timestamp_str, '%Y%m%d_%H%M')\n",
    "            df['timestamp'] = timestamp\n",
    "            if is_orderbook:\n",
    "                # Add order book type (bids/asks) from filename\n",
    "                ob_type = parts[3].split('.')[0]  # gets 'bids' or 'asks'\n",
    "                df['type'] = ob_type\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file}: {str(e)}\")\n",
    "            continue\n",
    "    if not dfs:\n",
    "        return pd.DataFrame()\n",
    "    combined_df = pd.concat(dfs).sort_values('timestamp')\n",
    "    # For order book data, ensure numeric columns\n",
    "    if is_orderbook:\n",
    "        combined_df['price'] = pd.to_numeric(combined_df['price'], errors='coerce')\n",
    "        combined_df['amount'] = pd.to_numeric(combined_df['amount'], errors='coerce')\n",
    "        combined_df.dropna(subset=['price', 'amount'], inplace=True)\n",
    "    return combined_df\n",
    "\n",
    "def enforce_nanosecond_precision(df):\n",
    "    \"\"\"Convert all datetime columns to datetime64[ns, UTC]\"\"\"\n",
    "    if df is None:\n",
    "        return df\n",
    "    df = df.copy()\n",
    "    datetime_cols = [col for col in df.columns if pd.api.types.is_datetime64_any_dtype(df[col])]\n",
    "    for col in datetime_cols:\n",
    "        # Ensure UTC (handles both naive and aware)\n",
    "        if not pd.api.types.is_datetime64tz_dtype(df[col]):\n",
    "            df[col] = pd.to_datetime(df[col]).dt.tz_localize('UTC')\n",
    "        else:\n",
    "            df[col] = pd.to_datetime(df[col]).dt.tz_convert('UTC')\n",
    "        # Force nanosecond precision\n",
    "        df[col] = pd.to_datetime(df[col], utc=True).astype('datetime64[ns, UTC]')\n",
    "    return df\n",
    "\n",
    "def get_eth_trade_size(trade):\n",
    "    \"\"\"Extract ETH and USDT amounts from trade row, handles both DataFrame row and dict input.\"\"\"\n",
    "    # Allow both DataFrame row and dict\n",
    "    trade_type = trade['trade_type'].upper()\n",
    "    # Accept both 'sell' and 'WETH_SELL'\n",
    "    if trade_type in ['WETH_SELL', 'SELL']:\n",
    "        return {\n",
    "            'eth_amount': trade['sold_amount'],\n",
    "            'usdt_amount': trade['bought_amount'],\n",
    "            'price_per_eth': trade['price_per_eth'],\n",
    "            'direction': 'sell'}\n",
    "    else:  # WETH_BUY or BUY\n",
    "        return {\n",
    "            'eth_amount': trade['bought_amount'],\n",
    "            'usdt_amount': trade['sold_amount'],\n",
    "            'price_per_eth': trade['price_per_eth'],\n",
    "            'direction': 'buy'}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load 1inch trade data\n",
    "    oneinch_df = pd.read_csv('1inch/oneinch_weth_usdt_trades.csv')\n",
    "    oneinch_df['block_time'] = pd.to_datetime(oneinch_df['block_time'])\n",
    "\n",
    "    # Load Binance data\n",
    "    ohlcv_df = load_binance_data('Binance/ETHUSDT_*_ohlcv.csv')\n",
    "    bids_df = load_binance_data('Binance/ETHUSDT_*_bids.csv', is_orderbook=True)\n",
    "    asks_df = load_binance_data('Binance/ETHUSDT_*_asks.csv', is_orderbook=True)\n",
    "\n",
    "    # Combine bids/asks into single orderbook DataFrame\n",
    "    orderbook_df = pd.concat([bids_df, asks_df]).sort_values(['timestamp', 'type', 'price'])\n",
    "    orderbook_df = orderbook_df.groupby(['timestamp', 'type']).apply(\n",
    "        lambda x: x.sort_values('price', ascending=(x.name[1] == 'asks'))\n",
    "    ).reset_index(drop=True)\n",
    "    orderbook_df['cum_amount'] = orderbook_df.groupby(['timestamp', 'type'])['amount'].cumsum()\n",
    "\n",
    "    # Enforce consistent datetime precision\n",
    "    oneinch_df = enforce_nanosecond_precision(oneinch_df)\n",
    "    ohlcv_df = enforce_nanosecond_precision(ohlcv_df)\n",
    "    orderbook_df = enforce_nanosecond_precision(orderbook_df)\n",
    "\n",
    "    # Create minute-level timestamps for alignment\n",
    "    oneinch_df['minute'] = oneinch_df['block_time'].dt.floor('min')\n",
    "    ohlcv_df['minute'] = ohlcv_df['timestamp'].dt.floor('min')\n",
    "    orderbook_df['minute'] = orderbook_df['timestamp'].dt.floor('min')\n",
    "\n",
    "    # --- Trade Filtering and Analysis ---\n",
    "    skipped_trades = {\n",
    "        'no_orderbook': {'count': 0, 'examples': []},\n",
    "        'small_size': {'count': 0, 'examples': []},\n",
    "        'time_alignment': {'count': 0, 'examples': []}}\n",
    "\n",
    "    # Pre-calc time boundaries\n",
    "    ob_min_time = orderbook_df['minute'].min()\n",
    "    ob_max_time = orderbook_df['minute'].max()\n",
    "\n",
    "    # Analyze trades that will be skipped (for reporting)\n",
    "    for idx, trade in oneinch_df.iterrows():\n",
    "        trade_details = get_eth_trade_size(trade)\n",
    "        eth_amount = trade_details['eth_amount']\n",
    "        trade_info = {\n",
    "            'time': trade['block_time'],\n",
    "            'size': eth_amount,\n",
    "            'pool': trade.get('pool_name', 'unknown'),\n",
    "            'tx_hash': trade['tx_hash']}\n",
    "        trade_minute = trade['minute']\n",
    "\n",
    "        # Check time alignment\n",
    "        if not (ob_min_time <= trade_minute <= ob_max_time):\n",
    "            skipped_trades['time_alignment']['count'] += 1\n",
    "            skipped_trades['time_alignment']['examples'].append(trade_info)\n",
    "            continue\n",
    "\n",
    "        # Check order book exists\n",
    "        ob_data = orderbook_df[orderbook_df['minute'] == trade_minute]\n",
    "        if ob_data.empty:\n",
    "            skipped_trades['no_orderbook']['count'] += 1\n",
    "            skipped_trades['no_orderbook']['examples'].append(trade_info)\n",
    "            continue\n",
    "\n",
    "        # Check trade size\n",
    "        if eth_amount < SMALL_TRADE_THRESHOLD:\n",
    "            skipped_trades['small_size']['count'] += 1\n",
    "            skipped_trades['small_size']['examples'].append(trade_info)\n",
    "\n",
    "    # --- Data Verification & Reporting ---\n",
    "    print(\"\\n=== Data Verification ===\")\n",
    "    print(\"Post-correction datetime types:\")\n",
    "    print(\"1inch:\", oneinch_df['block_time'].dtype)\n",
    "    print(\"OHLCV:\", ohlcv_df['timestamp'].dtype)\n",
    "    print(\"Orderbook:\", orderbook_df['timestamp'].dtype)\n",
    "\n",
    "    print(\"\\n1inch data sample:\")\n",
    "    print(\"1inch head:\\n\", oneinch_df[['block_time', 'trade_type', 'sold_amount', 'bought_amount', 'price_per_eth']].head(3))\n",
    "    print(\"1inch tail:\\n\", oneinch_df[['block_time', 'trade_type', 'sold_amount', 'bought_amount', 'price_per_eth']].tail(3))\n",
    "    print(\"\\nBinance OHLCV head:\\n\", ohlcv_df.head(3))\n",
    "    print(\"\\nBinance OHLCV tail:\\n\", ohlcv_df.tail(3))\n",
    "    print(\"\\nBinance Order book bids head:\\n\", orderbook_df[orderbook_df['type'] == 'bids'].head(3))\n",
    "    print(\"\\nBinance Order book bids tail:\\n\", orderbook_df[orderbook_df['type'] == 'bids'].tail(3))\n",
    "\n",
    "    print(\"\\nData ranges:\")\n",
    "    print(\"1inch range:\", oneinch_df['block_time'].min(), \"to\", oneinch_df['block_time'].max())\n",
    "    print(\"Binance OHLCV range:\", ohlcv_df['timestamp'].min(), \"to\", ohlcv_df['timestamp'].max())\n",
    "\n",
    "    print(\"\\nRecord counts:\")\n",
    "    print(f\"1inch trades: {len(oneinch_df)}\")\n",
    "    print(f\"Binance OHLCV: {len(ohlcv_df)}\")\n",
    "    print(f\"Binance Order Book entries: {len(orderbook_df)}\")\n",
    "\n",
    "    print(\"\\n=== Trade Filtering Report ===\")\n",
    "    print(f\"Total trades: {len(oneinch_df)}\")\n",
    "    print(f\"Trades that will be skipped: {sum(v['count'] for v in skipped_trades.values())}\")\n",
    "\n",
    "    print(\"\\nSKIP REASONS:\")\n",
    "    for reason, data in skipped_trades.items():\n",
    "        print(f\"\\n{reason.replace('_', ' ').title()}: {data['count']}\")\n",
    "        if data['examples']:\n",
    "            if reason in ['time_alignment', 'no_orderbook']:\n",
    "                example = data['examples'][-1]\n",
    "                print(f\"First example - Time: {example['time']}, Size: {example['size']} ETH\")\n",
    "            else:\n",
    "                example = data['examples'][0]\n",
    "                print(f\"Last Example - Time: {example['time']}, Size: {example['size']} ETH\")\n",
    "\n",
    "    # Save preprocessed data for downstream steps\n",
    "    os.makedirs('processed_data', exist_ok=True)\n",
    "    oneinch_df.to_pickle('processed_data/oneinch_df.pkl')\n",
    "    ohlcv_df.to_pickle('processed_data/ohlcv_df.pkl')\n",
    "    orderbook_df.to_pickle('processed_data/orderbook_df.pkl')\n",
    "\n",
    "    print(\"\\nPreprocessed .pkl data saved to 'processed_data' dir for Step2b & 2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7df1b44b-add8-42c4-bf78-255ed2766c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data...\n",
      "\n",
      "Running flow internalization analysis...\n",
      "\n",
      "=== Analysis Results ===\n",
      "Total trades analyzed: 1017\n",
      "\n",
      "Strategy Performance Summary:\n",
      "           hedge_pnl  warehouse_pnl\n",
      "count    1017.000000    1017.000000\n",
      "mean     -382.344708       3.509384\n",
      "std      5911.043910     468.929301\n",
      "min   -143999.379200   -7117.269100\n",
      "25%        -0.782800      -0.983600\n",
      "50%        -0.039900       0.038600\n",
      "75%         0.020700       1.453900\n",
      "max        12.965700   11753.995600\n",
      "\n",
      "Corr Analysis:\n",
      "Average Px Corr: 0.28\n",
      "Average Volume Corr: -0.08\n",
      "\n",
      "Recommendation Distribution:\n",
      "recommendation\n",
      "Warehouse    570\n",
      "Hedge        447\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Visualizations saved to 'results' directory\n",
      "\n",
      "Analysis complete!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step2bi - Flow Internalization Analysis\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====================== CONFIG ======================\n",
    "BINANCE_TAKER_FEE = 0.0002             # 0.02% taker fee\n",
    "BINANCE_MAKER_FEE = 0.0000             # 0.00% maker fee\n",
    "SMALL_TRADE_THRESHOLD = 0.01           # Min ETH trade size to analyze\n",
    "SLIPPAGE_MODEL = lambda x: 0.0002 * x  # 0.0002 Slippage as % of trade size\n",
    "LOOKFORWARD_WINDOW = 120               # Minutes (fwd) for warehouse strat analysis\n",
    "CORRELATION_WINDOW = 2.5               # Minutes before/after 1nch trade for corr analysis \n",
    "\n",
    "def get_eth_trade_size(trade):\n",
    "    \"\"\"Extract all necessary details directly from the trade record\"\"\"\n",
    "    trade_type = str(trade['trade_type']).upper()\n",
    "    if trade_type in ['WETH_SELL', 'SELL']:\n",
    "        return {\n",
    "            'eth_amount': trade['sold_amount'],\n",
    "            'usdt_amount': trade['bought_amount'],\n",
    "            'price_per_eth': trade['price_per_eth'],\n",
    "            'direction': 'sell'}\n",
    "    else:  # WETH_BUY or BUY\n",
    "        return {\n",
    "            'eth_amount': trade['bought_amount'],\n",
    "            'usdt_amount': trade['sold_amount'],\n",
    "            'price_per_eth': trade['price_per_eth'],\n",
    "            'direction': 'buy'}\n",
    "\n",
    "# ====================== CORE FUNCTIONS ======================\n",
    "def calculate_hedging_pnl(trade, orderbook_snapshot):\n",
    "    \"\"\"Calc PNL from immediate hedging on Binance\"\"\"\n",
    "    try:\n",
    "        trade_details = get_eth_trade_size(trade)\n",
    "        eth_amount = trade_details['eth_amount']\n",
    "\n",
    "        if trade_details['direction'] == 'sell':\n",
    "            # Hedge by SELLING ETH on Binance, ie. hit highest bid\n",
    "            execution_price = orderbook_snapshot[orderbook_snapshot['type'] == 'bids']['price'].max()\n",
    "            slippage = SLIPPAGE_MODEL(eth_amount)\n",
    "            executed_price = execution_price * (1 - slippage)\n",
    "            # PnL: Hedge Price - 1inch Price\n",
    "            pnl = (executed_price - trade_details['price_per_eth']) * eth_amount\n",
    "        else:  # buy\n",
    "            # Hedge by BUYING ETH on Binance, i.e., lift the lowest ask\n",
    "            execution_price = orderbook_snapshot[orderbook_snapshot['type'] == 'asks']['price'].min()\n",
    "            slippage = SLIPPAGE_MODEL(eth_amount)\n",
    "            executed_price = execution_price * (1 + slippage)\n",
    "            # PnL: 1inch Price - Hedge Price\n",
    "            pnl = (trade_details['price_per_eth'] - executed_price) * eth_amount\n",
    "\n",
    "        # Subtract fee (always a cost)\n",
    "        fee = BINANCE_TAKER_FEE\n",
    "        pnl -= (executed_price * eth_amount * fee)\n",
    "\n",
    "        return pnl, executed_price\n",
    "    except Exception as e:\n",
    "        print(f\"Error in hedging calc for trade {trade.get('tx_hash', 'unknown')}: {str(e)}\")\n",
    "        return np.nan, np.nan\n",
    "\n",
    "def calculate_warehousing_pnl(trade, ohlcv_df, lookforward_window=LOOKFORWARD_WINDOW):\n",
    "    \"\"\"Calc PNL from warehousing risk\"\"\"\n",
    "    try:\n",
    "        trade_details = get_eth_trade_size(trade)\n",
    "        eth_amount = trade_details['eth_amount']\n",
    "        trade_time = trade['block_time']\n",
    "        end_time = trade_time + timedelta(minutes=lookforward_window)\n",
    "        \n",
    "        historical = ohlcv_df[\n",
    "            (ohlcv_df['timestamp'] >= trade_time) & \n",
    "            (ohlcv_df['timestamp'] <= end_time)].copy()\n",
    "        \n",
    "        if historical.empty:\n",
    "            return np.nan, np.nan, np.nan, np.nan\n",
    "        \n",
    "        # VWAP calc\n",
    "        total_volume = historical['volume'].sum()\n",
    "        if total_volume > 0:\n",
    "            warehouse_price = (historical['close'] * historical['volume']).sum() / total_volume\n",
    "        else:\n",
    "            warehouse_price = historical['close'].mean()\n",
    "\n",
    "        # PnL Calc\n",
    "        if trade_details['direction'] == 'sell':\n",
    "            pnl = (warehouse_price - trade_details['price_per_eth']) * eth_amount\n",
    "        else:  # buy\n",
    "            pnl = (trade_details['price_per_eth'] - warehouse_price) * eth_amount\n",
    "            \n",
    "        return pnl, warehouse_price, np.nan, np.nan  \n",
    "    except Exception as e:\n",
    "        print(f\"Error in warehouse calc for trade {trade.get('tx_hash', 'unknown')}: {str(e)}\")\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "def calculate_correlations(trade, oneinch_df, ohlcv_df, correlation_window):\n",
    "    \"\"\"Calc px & volume corrs between 1inch and Binance with improved handling\"\"\"\n",
    "    try:\n",
    "        window = pd.Timedelta(minutes=correlation_window)\n",
    "        start_time = trade['block_time'] - window\n",
    "        end_time = trade['block_time'] + window\n",
    "        \n",
    "        # Get Binance data in window\n",
    "        binance_data = ohlcv_df[\n",
    "            (ohlcv_df['timestamp'] >= start_time) & \n",
    "            (ohlcv_df['timestamp'] <= end_time)]\n",
    "        \n",
    "        # Get 1inch trades in same window (excl current trade)\n",
    "        oneinch_data = oneinch_df[\n",
    "            (oneinch_df['block_time'] >= start_time) & \n",
    "            (oneinch_df['block_time'] <= end_time) & \n",
    "            (oneinch_df['tx_hash'] != trade['tx_hash'])]\n",
    "        \n",
    "        # Initialize results as NaN\n",
    "        price_corr = volume_corr = np.nan\n",
    "        min_points = 3  # Minimum data pts required for correlation\n",
    "        \n",
    "        # Price Corr\n",
    "        if len(binance_data) >= min_points and len(oneinch_data) >= min_points:\n",
    "            binance_px = binance_data.set_index('timestamp')['close'].resample('1min').last().ffill()\n",
    "            oneinch_px = oneinch_data.set_index('block_time')['price_per_eth'].resample('1min').last().ffill()\n",
    "            aligned_px = pd.concat([binance_px.rename('binance'), oneinch_px.rename('oneinch')], axis=1).dropna()\n",
    "            if len(aligned_px) >= min_points:\n",
    "                with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                    price_corr = aligned_px['binance'].corr(aligned_px['oneinch'])\n",
    "        \n",
    "        # Volume Corr\n",
    "        if len(binance_data) >= min_points and len(oneinch_data) >= min_points:\n",
    "            try:\n",
    "                binance_vol = binance_data.set_index('timestamp')['volume'].resample('1min').sum()\n",
    "                oneinch_vol = oneinch_data.apply(get_eth_trade_size, axis=1).apply(lambda x: x['eth_amount']).groupby(oneinch_data['block_time'].dt.floor('min')).sum()\n",
    "                binance_vol_norm = (binance_vol - binance_vol.mean()) / (binance_vol.std() if binance_vol.std() != 0 else 1)\n",
    "                oneinch_vol_norm = (oneinch_vol - oneinch_vol.mean()) / (oneinch_vol.std() if oneinch_vol.std() != 0 else 1)\n",
    "                vol_aligned = pd.concat([binance_vol_norm.rename('binance_vol'), oneinch_vol_norm.rename('oneinch_vol')], axis=1).dropna()\n",
    "                if len(vol_aligned) >= min_points:\n",
    "                    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                        volume_corr = vol_aligned['binance_vol'].corr(vol_aligned['oneinch_vol'])\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        return (\n",
    "            round(price_corr, 4) if not np.isnan(price_corr) else np.nan,\n",
    "            round(volume_corr, 4) if not np.isnan(volume_corr) else np.nan)\n",
    "    except Exception as e:\n",
    "        print(f\"Correlation error for trade {trade.get('tx_hash', 'unknown')}: {str(e)}\")\n",
    "        return np.nan, np.nan\n",
    "\n",
    "def flow_internalization_model(oneinch_df, ohlcv_df, orderbook_df):\n",
    "    \"\"\"Run the flow internalization analysis with complete output\"\"\"\n",
    "    results = []\n",
    "    ob_min_time = orderbook_df['minute'].min()\n",
    "    ob_max_time = orderbook_df['minute'].max()\n",
    "    ob_times = set(orderbook_df['minute'])\n",
    "    \n",
    "    for idx, trade in oneinch_df.iterrows():\n",
    "        trade_minute = trade['minute']\n",
    "        trade_details = get_eth_trade_size(trade)\n",
    "        eth_amount = trade_details['eth_amount']\n",
    "        \n",
    "        # Skip if out of orderbook time or missing orderbook for this minute\n",
    "        if trade_minute < ob_min_time or trade_minute > ob_max_time:\n",
    "            continue\n",
    "        if trade_minute not in ob_times:\n",
    "            continue\n",
    "        if eth_amount < SMALL_TRADE_THRESHOLD:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            ob_data = orderbook_df[orderbook_df['minute'] == trade_minute]\n",
    "            if ob_data.empty:\n",
    "                continue\n",
    "                \n",
    "            hedge_pnl, hedge_price = calculate_hedging_pnl(trade, ob_data)\n",
    "            warehouse_pnl, warehouse_price, _, _ = calculate_warehousing_pnl(trade, ohlcv_df, LOOKFORWARD_WINDOW)\n",
    "            \n",
    "            # Calc Corrs\n",
    "            price_corr, volume_corr = calculate_correlations(trade, oneinch_df, ohlcv_df, CORRELATION_WINDOW)\n",
    "            \n",
    "            recommendation = \"Warehouse\" if warehouse_pnl > hedge_pnl else \"Hedge\"\n",
    "            \n",
    "            results.append({\n",
    "                'trade_time': trade['block_time'],\n",
    "                'trade_type': trade['trade_type'],\n",
    "                'eth_amount': round(eth_amount, 4),\n",
    "                'usdt_value': round(trade_details['usdt_amount'], 4),\n",
    "                '1inch_price': round(trade_details['price_per_eth'], 4),\n",
    "                'hedge_price': round(hedge_price, 4),\n",
    "                'hedge_pnl': round(hedge_pnl, 4),\n",
    "                'warehouse_price': round(warehouse_price, 4),\n",
    "                'warehouse_pnl': round(warehouse_pnl, 4),\n",
    "                'price_corr': price_corr,  \n",
    "                'volume_corr': volume_corr,  \n",
    "                'recommendation': recommendation,\n",
    "                'tx_hash': trade['tx_hash'],\n",
    "                'pool_name': trade.get('pool_name', 'unknown')})\n",
    "       \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing trade {trade.get('tx_hash', 'unknown')}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ====================== MAIN EXECUTION ======================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading preprocessed data...\")\n",
    "    oneinch_df = pd.read_pickle('processed_data/oneinch_df.pkl')\n",
    "    ohlcv_df = pd.read_pickle('processed_data/ohlcv_df.pkl')\n",
    "    orderbook_df = pd.read_pickle('processed_data/orderbook_df.pkl')\n",
    "    \n",
    "    # Convert timestamps\n",
    "    oneinch_df['block_time'] = pd.to_datetime(oneinch_df['block_time'])\n",
    "    ohlcv_df['timestamp'] = pd.to_datetime(ohlcv_df['timestamp'])\n",
    "    orderbook_df['timestamp'] = pd.to_datetime(orderbook_df['timestamp'])\n",
    "    \n",
    "    # Create minute columns\n",
    "    oneinch_df['minute'] = oneinch_df['block_time'].dt.floor('min')\n",
    "    ohlcv_df['minute'] = ohlcv_df['timestamp'].dt.floor('min')\n",
    "    orderbook_df['minute'] = orderbook_df['timestamp'].dt.floor('min')\n",
    "\n",
    "    # Run analysis\n",
    "    print(\"\\nRunning flow internalization analysis...\")\n",
    "    results_df = flow_internalization_model(oneinch_df, ohlcv_df, orderbook_df)\n",
    "\n",
    "    # Sort by trade_time (earliest first)\n",
    "    results_df = results_df.sort_values('trade_time')\n",
    "\n",
    "    # Ensure consistent formatting in final output\n",
    "    float_cols = results_df.select_dtypes(include=[np.float64]).columns\n",
    "    results_df[float_cols] = results_df[float_cols].round(4)\n",
    "\n",
    "    # Save results\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    results_df.to_csv('results/flow_internalization_results.csv', index=False, float_format='%.4f')\n",
    " \n",
    "    print(\"\\n=== Analysis Results ===\")\n",
    "    print(f\"Total trades analyzed: {len(results_df)}\")\n",
    "    \n",
    "    if not results_df.empty:\n",
    "        print(\"\\nStrategy Performance Summary:\")\n",
    "        print(results_df[['hedge_pnl', 'warehouse_pnl']].describe())\n",
    "        \n",
    "        print(\"\\nCorr Analysis:\")\n",
    "        print(f\"Average Px Corr: {results_df['price_corr'].mean():.2f}\")\n",
    "        print(f\"Average Volume Corr: {results_df['volume_corr'].mean():.2f}\")\n",
    "        \n",
    "        print(\"\\nRecommendation Distribution:\")\n",
    "        print(results_df['recommendation'].value_counts())\n",
    "        \n",
    "        # Plot trade sizes in ETH\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        results_df['eth_amount'].hist(bins=50)\n",
    "        plt.title('Processed Trade Sizes (ETH)')\n",
    "        plt.xlabel('ETH Amount')\n",
    "        plt.ylabel('# Trades')\n",
    "        plt.xlim(0, 60)  # This sets x-axis range from 0 to 60\n",
    "        plt.savefig('results/processed_trade_sizes.png')\n",
    "        plt.close()\n",
    "   \n",
    "        print(\"\\nVisualizations saved to 'results' directory\")    \n",
    "    print(\"\\nAnalysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f52a0a9-2142-4d6c-b810-ae821833a15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting slippage calibration at 2025-05-22T21:47:06.000974\n",
      "Loading data files...\n",
      "Processing 1795 trades...\n",
      "\n",
      "Analysis completed at 2025-05-22T21:47:06.798730\n",
      "Results saved to results/slippage_comparison_vs_orderbook.csv\n",
      "Total trades analyzed: 445\n",
      "Breakdown:\n",
      "- Trades with orderbook data: 316\n",
      "- Trades fully filled: 316\n",
      "\n",
      "Sample output (first 3 rows):\n",
      "                   block_time          orderbook_minute trade_type eth_amount  orderbook_found   top_px formulaic_px orderbook_vwap_px formulaic_slippage_pct orderbook_actual_slippage_pct vwap_fill_completed vwap_total_filled\n",
      "444 2025-05-05 08:17:47+00:00 2025-05-05 08:17:00+00:00  WETH_SELL       2.20             True  1825.41      1824.61           1825.41                  0.044                         0.000                True              2.20\n",
      "443 2025-05-05 08:40:35+00:00 2025-05-05 08:40:00+00:00  WETH_SELL      20.04             True  1828.71      1821.38           1828.66                  0.401                         0.003                True             20.04\n",
      "442 2025-05-05 08:45:23+00:00 2025-05-05 08:45:00+00:00  WETH_SELL       3.00             True  1829.89      1828.79           1829.89                  0.060                         0.000                True              3.00\n"
     ]
    }
   ],
   "source": [
    "# Step2b-ii Slippage Parameter - Calibration\n",
    "# Calibrate slippage formula with actual Orderbook liquidity\n",
    "'''\n",
    "Script:\n",
    "Loads your saved 1inch, bids, asks DF (from your Step 2a outputs).\n",
    "For each trade (min size specified below), finds corresp. orderbook at the trade's minute.\n",
    "Compares formulaic slippage model to actual Binance ETH/USD Orderbook VWAP for req'd trade size.\n",
    "Outputs a CSV with both slippages for comparison\n",
    "Even though Step2a checks for order book existence at minute level, actual order book might not hv enough depth for large trades\n",
    "Script checks vwap_fill_completed which fails when order book can't fully absorb trade size\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Config ---\n",
    "MIN_TRADE_SIZE_ETH = 1.0  # Minimum ETH trade size to analyze\n",
    "SLIPPAGE_MODEL = lambda x: 0.0002 * x  # eg. 0.0002 =  0.02% per ETH\n",
    "\n",
    "def get_eth_trade_size(trade):\n",
    "    trade_type = str(trade['trade_type']).upper()\n",
    "    if trade_type in ['WETH_SELL', 'SELL']:\n",
    "        return trade['sold_amount']\n",
    "    else:  # WETH_BUY or BUY\n",
    "        return trade['bought_amount']\n",
    "\n",
    "def calculate_formulaic_slippage_price(side, top_px, eth_amount, slippage_model):\n",
    "    slippage = slippage_model(eth_amount)\n",
    "    if side == \"sell\":\n",
    "        executed_price = top_px * (1 - slippage)\n",
    "        slippage_pct = slippage * 100  # Convert to %\n",
    "    else:\n",
    "        executed_price = top_px * (1 + slippage)\n",
    "        slippage_pct = slippage * 100  # Convert to %\n",
    "    return executed_price, slippage_pct\n",
    "\n",
    "def calculate_orderbook_vwap(orderbook_levels, eth_amount):\n",
    "    \"\"\"\n",
    "    Calc VWAP & slippage using actual orderbook levels.\n",
    "    orderbook_levels:    pd.DataFrame with columns ['price', 'amount'] sorted best-to-worst\n",
    "    eth_amount:          amount to fill\n",
    "    Returns:             vwap_price, slippage_percent, total_filled\n",
    "    \"\"\"\n",
    "    amount_remaining = eth_amount\n",
    "    total_cost = 0.0\n",
    "    total_filled = 0.0\n",
    "\n",
    "    for idx, row in orderbook_levels.iterrows():\n",
    "        px = float(row['price'])\n",
    "        size = float(row['amount'])\n",
    "        take = min(size, amount_remaining)\n",
    "        total_cost += px * take\n",
    "        total_filled += take\n",
    "        amount_remaining -= take\n",
    "        if amount_remaining <= 1e-8:\n",
    "            break\n",
    "\n",
    "    if total_filled == 0:\n",
    "        return float('nan'), float('nan'), 0\n",
    "\n",
    "    vwap = total_cost / total_filled\n",
    "    top_px = float(orderbook_levels.iloc[0]['price'])\n",
    "    actual_slippage_pct = abs(vwap - top_px) / top_px * 100\n",
    "    return vwap, actual_slippage_pct, total_filled\n",
    "\n",
    "def compare_slippage(trade_row, bids_df, asks_df):\n",
    "    eth_amount = get_eth_trade_size(trade_row)\n",
    "    trade_type = trade_row['trade_type']\n",
    "    orderbook_minute = trade_row['minute']\n",
    "    block_time = trade_row.get('block_time', pd.NaT)\n",
    "\n",
    "    if str(trade_type).upper() in ['WETH_SELL', 'SELL']:\n",
    "        side = \"sell\"\n",
    "        relevant_book = bids_df[bids_df['minute'] == orderbook_minute].sort_values('price', ascending=False)\n",
    "    else:\n",
    "        side = \"buy\"\n",
    "        relevant_book = asks_df[asks_df['minute'] == orderbook_minute].sort_values('price', ascending=True)\n",
    "\n",
    "    if relevant_book.empty:\n",
    "        return {'block_time': block_time, 'orderbook_minute': orderbook_minute, 'trade_type': trade_type,\n",
    "            'eth_amount': eth_amount, 'orderbook_found': False}\n",
    "\n",
    "    top_px = float(relevant_book.iloc[0]['price'])\n",
    "\n",
    "    # Formulaic slippage\n",
    "    formulaic_px, formulaic_slip_pct = calculate_formulaic_slippage_price(side, top_px, eth_amount, SLIPPAGE_MODEL)\n",
    "\n",
    "    # Actual orderbook VWAP slippage\n",
    "    vwap_px, actual_slip_pct, total_filled = calculate_orderbook_vwap(relevant_book[['price', 'amount']], eth_amount)\n",
    "    vwap_fill_completed = total_filled >= eth_amount * 0.999  # Allow 0.1% tolerance\n",
    "\n",
    "    return {\n",
    "        'block_time': block_time,\n",
    "        'orderbook_minute': orderbook_minute,\n",
    "        'trade_type': trade_type,\n",
    "        'eth_amount': eth_amount,\n",
    "        'orderbook_found': True,\n",
    "        'top_px': top_px,\n",
    "        'formulaic_px': formulaic_px,\n",
    "        'formulaic_slippage_pct': formulaic_slip_pct,\n",
    "        'orderbook_vwap_px': vwap_px,\n",
    "        'orderbook_actual_slippage_pct': actual_slip_pct,\n",
    "        'vwap_fill_completed': vwap_fill_completed,\n",
    "        'vwap_total_filled': total_filled}\n",
    "\n",
    "def format_results_df(df):\n",
    "    \"\"\"Apply specific decimal formatting to different column types\"\"\"\n",
    "    df_formatted = df.copy()\n",
    "    \n",
    "    # Price columns - 2 decimals (force 2 decimal places)\n",
    "    price_cols = ['top_px', 'formulaic_px', 'orderbook_vwap_px']\n",
    "    for col in price_cols:\n",
    "        if col in df_formatted.columns:\n",
    "            df_formatted[col] = df_formatted[col].apply(\n",
    "                lambda x: f\"{float(x):.2f}\" if pd.notna(x) else \"\")\n",
    "    \n",
    "    # % columns - 3 decimals\n",
    "    pct_cols = ['formulaic_slippage_pct', 'orderbook_actual_slippage_pct']\n",
    "    for col in pct_cols:\n",
    "        if col in df_formatted.columns:\n",
    "            df_formatted[col] = df_formatted[col].apply(\n",
    "                lambda x: f\"{x:.3f}\" if pd.notna(x) else \"\")\n",
    "    \n",
    "    # Amount columns - 2 decimals\n",
    "    amount_cols = ['eth_amount', 'vwap_total_filled']\n",
    "    for col in amount_cols:\n",
    "        if col in df_formatted.columns:\n",
    "            df_formatted[col] = df_formatted[col].apply(\n",
    "                lambda x: f\"{x:.2f}\" if pd.notna(x) else \"\")\n",
    "    \n",
    "    return df_formatted\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Starting slippage calibration at {datetime.now().isoformat()}\")\n",
    "    \n",
    "    # Load processed data\n",
    "    print(\"Loading data files...\")\n",
    "    oneinch_df = pd.read_pickle(\"processed_data/oneinch_df.pkl\")\n",
    "    orderbook_df = pd.read_pickle(\"processed_data/orderbook_df.pkl\")\n",
    "\n",
    "    # Process orderbook data\n",
    "    bids_df = orderbook_df[orderbook_df['type'] == 'bids'].copy()\n",
    "    asks_df = orderbook_df[orderbook_df['type'] == 'asks'].copy()\n",
    "    \n",
    "    # Convert to numeric types\n",
    "    for df in [bids_df, asks_df]:\n",
    "        df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "        df['amount'] = pd.to_numeric(df['amount'], errors='coerce')\n",
    "    \n",
    "    # Process trades\n",
    "    print(f\"Processing {len(oneinch_df)} trades...\")\n",
    "    results = []\n",
    "    for idx, row in oneinch_df.iterrows():\n",
    "        eth_amount = get_eth_trade_size(row)\n",
    "        if eth_amount < MIN_TRADE_SIZE_ETH:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            comp = compare_slippage(row, bids_df, asks_df)\n",
    "            results.append(comp)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing trade {idx}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Create and format results DF\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('block_time', ascending=True)\n",
    "    \n",
    "    # Reorder columns\n",
    "    col_order = ['block_time', 'orderbook_minute', 'trade_type', 'eth_amount', 'orderbook_found', 'top_px', 'formulaic_px', 'orderbook_vwap_px',\n",
    "        'formulaic_slippage_pct', 'orderbook_actual_slippage_pct', 'vwap_fill_completed', 'vwap_total_filled']\n",
    "    results_df = results_df[[c for c in col_order if c in results_df.columns]]\n",
    "    \n",
    "    # Format numbers\n",
    "    formatted_df = format_results_df(results_df)\n",
    "    \n",
    "    # Save results\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    output_path = 'results/slippage_comparison_vs_orderbook.csv'\n",
    "    formatted_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\nAnalysis completed at {datetime.now().isoformat()}\")\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "    print(f\"Total trades analyzed: {len(results_df)}\")\n",
    "    print(f\"Breakdown:\")\n",
    "    print(f\"- Trades with orderbook data: {results_df['orderbook_found'].sum()}\")\n",
    "    print(f\"- Trades fully filled: {results_df['vwap_fill_completed'].sum()}\")\n",
    "    \n",
    "    # Show sample output\n",
    "    print(\"\\nSample output (first 3 rows):\")\n",
    "    print(formatted_df.head(3).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8c2f1fa-c6ce-40c4-b8b3-da983dd675b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading flow internalization data...\n",
      "\n",
      "=== Initial Values ===\n",
      "INITIAL_ETH: 100.00\n",
      "1inch_price: 1,832.9097\n",
      "INITIAL_USDT: 100,000.00\n",
      "Initial Portfolio Value (USDT): 283,290.97\n",
      "\n",
      "=== First 5 Trades ===\n",
      "                  trade_time trade_type  eth_amount  usdt_value  1inch_price recommendation  hedge_pnl  warehouse_pnl  ETH_Net_Cum_Balance  USDT_Cum_Balance  Portfolio_Value    Cum_PnL\n",
      "0  2025-05-05 08:04:23+00:00  WETH_SELL        0.03       49.49     1,832.91      Warehouse       0.00          -0.16               100.03         99,950.35       283,290.81      -0.16\n",
      "1  2025-05-05 08:10:11+00:00   WETH_BUY        0.02       30.00     1,699.44          Hedge      -2.23           0.00               100.03         99,948.12       269,938.13 -13,352.84\n",
      "2  2025-05-05 08:11:23+00:00  WETH_SELL        0.06      109.50     1,824.94      Warehouse       0.00           0.08               100.09         99,838.70       282,491.43    -799.54\n",
      "3  2025-05-05 08:15:47+00:00  WETH_SELL        0.01       22.71     1,821.61      Warehouse       0.00           0.06               100.10         99,816.05       282,158.43  -1,132.54\n",
      "4  2025-05-05 08:17:11+00:00  WETH_SELL        0.01       19.91     1,822.87      Warehouse       0.00           0.03               100.11         99,796.17       282,284.40  -1,006.57\n",
      "\n",
      "=== Last 5 Trades ===\n",
      "                     trade_time trade_type  eth_amount  usdt_value  1inch_price recommendation  hedge_pnl  warehouse_pnl  ETH_Net_Cum_Balance  USDT_Cum_Balance  Portfolio_Value   Cum_PnL\n",
      "1012  2025-05-07 09:05:59+00:00   WETH_BUY        0.54    1,000.00     1,843.29      Warehouse       0.00           1.07             1,650.63     -2,663,793.52       378,804.83 95,513.86\n",
      "1013  2025-05-07 09:07:23+00:00   WETH_BUY        0.03       56.69     1,841.97      Warehouse       0.00           0.02             1,650.60     -2,663,736.81       376,616.57 93,325.60\n",
      "1014  2025-05-07 09:07:59+00:00   WETH_BUY        0.14      250.00     1,846.00      Warehouse       0.00           0.64             1,650.47     -2,663,486.17       383,271.16 99,980.19\n",
      "1015  2025-05-07 09:08:23+00:00  WETH_SELL       21.54   39,654.09     1,840.97      Warehouse       0.00           7.38             1,672.01     -2,703,132.89       374,976.20 91,685.23\n",
      "1016  2025-05-07 09:08:47+00:00  WETH_SELL        0.14      265.92     1,840.12      Warehouse       0.00           0.17             1,672.15     -2,703,398.63       373,554.15 90,263.18\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step2c. Flow Internalization Model - Inventory Aware\n",
    "'''\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def track_portfolio(flow_internalization_df):\n",
    "    \"\"\"\n",
    "    Tracks portfolio value and PnL based on flow internalization decisions\n",
    "    Args:      flow_internalization_df: DF w/trade details & recommendations\n",
    "        \n",
    "    Returns:   results_df: DataFrame with portfolio tracking results\n",
    "               initial_price: Starting ETH price\n",
    "               initial_portfolio_value: Starting portfolio value\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Initialize Balances\n",
    "    eth_balance = 100.0             # Start w/ ETH 100\n",
    "    usdt_balance = 100000.0         # Start w/ USDT 100,000\n",
    "    \n",
    "    # Get Initial Px & calc Initial Portfolio Value\n",
    "    initial_price = flow_internalization_df.iloc[0]['1inch_price']\n",
    "    initial_portfolio_value = eth_balance * initial_price + usdt_balance\n",
    "    \n",
    "    for idx, trade in flow_internalization_df.iterrows():\n",
    "        try:\n",
    "            # Get trade details\n",
    "            eth_amount = trade['eth_amount']\n",
    "            usdt_value = trade['usdt_value']\n",
    "            current_price = trade['1inch_price']\n",
    "            recommendation = trade['recommendation']\n",
    "            trade_type = trade['trade_type']\n",
    "            hedge_pnl = trade.get('hedge_pnl', 0)  # Default to 0 if column missing\n",
    "            warehouse_pnl = trade.get('warehouse_pnl', 0)\n",
    "            \n",
    "            # For Hedge trades (offset on Binance)\n",
    "            if recommendation == 'Hedge':\n",
    "                # ETH balance remains unchanged (pass-through)\n",
    "                # USDT balance only changes by hedge PnL\n",
    "                usdt_balance += hedge_pnl\n",
    "            \n",
    "            # For Warehouse trades (inventory changes)\n",
    "            elif recommendation == 'Warehouse':\n",
    "                if trade_type == 'WETH_SELL':\n",
    "                    # Client sells WETH to us - we receive WETH and give USDT\n",
    "                    eth_balance += eth_amount\n",
    "                    usdt_balance -= usdt_value\n",
    "                    # Apply warehouse PnL\n",
    "                    usdt_balance += warehouse_pnl\n",
    "                else:  # WETH_BUY\n",
    "                    # Client buys WETH from us - we give WETH and receive USDT\n",
    "                    eth_balance -= eth_amount\n",
    "                    usdt_balance += usdt_value\n",
    "                    # Apply warehouse PnL\n",
    "                    usdt_balance += warehouse_pnl\n",
    "            \n",
    "            # Calc current portfolio value\n",
    "            portfolio_value = eth_balance * current_price + usdt_balance\n",
    "            cum_pnl = portfolio_value - initial_portfolio_value\n",
    "            \n",
    "            # Record results\n",
    "            results.append({\n",
    "                'trade_time': trade['trade_time'],\n",
    "                'trade_type': trade_type,\n",
    "                'eth_amount': round(eth_amount, 4),\n",
    "                'usdt_value': round(usdt_value, 4),\n",
    "                '1inch_price': round(current_price, 4),\n",
    "                'recommendation': recommendation,\n",
    "                'hedge_pnl': round(hedge_pnl, 4) if recommendation == 'Hedge' else 0,\n",
    "                'warehouse_pnl': round(warehouse_pnl, 4) if recommendation == 'Warehouse' else 0,\n",
    "                'ETH_Net_Cum_Balance': round(eth_balance, 2),\n",
    "                'USDT_Cum_Balance': round(usdt_balance, 2),\n",
    "                'Portfolio_Value': round(portfolio_value, 2),\n",
    "                'Cum_PnL': round(cum_pnl, 2)})\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing trade at {trade['trade_time']}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(results), initial_price, initial_portfolio_value\n",
    "\n",
    "def main():\n",
    "    print(\"Loading flow internalization data...\")\n",
    "    \n",
    "    # Load and prepare data\n",
    "    flow_internalization_df = pd.read_csv('results/flow_internalization_results.csv')\n",
    "    \n",
    "    # Convert numeric columns\n",
    "    numeric_cols = ['eth_amount', 'usdt_value', '1inch_price', 'hedge_pnl', 'warehouse_pnl']\n",
    "    flow_internalization_df[numeric_cols] = flow_internalization_df[numeric_cols].apply(\n",
    "        pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Standardize trade_type values\n",
    "    flow_internalization_df['trade_type'] = flow_internalization_df['trade_type'].replace({\n",
    "        'WETH_SELL': 'WETH_SELL', 'WETH_BUY': 'WETH_BUY'})\n",
    "    \n",
    "    # Sort chronologically\n",
    "    flow_internalization_df = flow_internalization_df.sort_values('trade_time')\n",
    "    \n",
    "    # Run portfolio tracker\n",
    "    results_df, initial_price, initial_value = track_portfolio(flow_internalization_df)\n",
    "    \n",
    "    # Save results\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    results_df.to_csv('results/portfolio_tracking_results.csv', index=False, float_format='%.2f')\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n=== Initial Values ===\")\n",
    "    print(f\"INITIAL_ETH: 100.00\")\n",
    "    print(f\"1inch_price: {initial_price:,.4f}\")\n",
    "    print(f\"INITIAL_USDT: 100,000.00\")\n",
    "    print(f\"Initial Portfolio Value (USDT): {initial_value:,.2f}\")\n",
    "    \n",
    "    print(\"\\n=== First 5 Trades ===\")\n",
    "    print(results_df.head().to_string(float_format=lambda x: f\"{x:,.2f}\" if isinstance(x, (int, float)) else str(x)))\n",
    "    \n",
    "    print(\"\\n=== Last 5 Trades ===\")\n",
    "    print(results_df.tail().to_string(float_format=lambda x: f\"{x:,.2f}\" if isinstance(x, (int, float)) else str(x)))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce0671e0-0965-4244-ba0e-28b81caf3164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trade_time', 'trade_type', 'eth_amount', 'usdt_value', '1inch_price', 'recommendation', 'hedge_pnl', 'warehouse_pnl', 'ETH_Net_Cum_Balance', 'USDT_Cum_Balance', 'Portfolio_Value', 'Cum_PnL']\n"
     ]
    }
   ],
   "source": [
    "print(results.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "915aae5f-2764-48ec-867e-54e2718e1a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At end of Step2d - load up the .html generated file & watch the portfolio evolve thru time.\n",
    "#Step2d_i Visualization Setup start\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def prepare_inventory_data(results_df):\n",
    "    # Prepare & downsample Inventory data for visualization\n",
    "    # Convert 'trade_time' to datetime if not already\n",
    "    results_df['trade_time'] = pd.to_datetime(results_df['trade_time'])\n",
    "    \n",
    "    # Select only numeric columns for aggregation\n",
    "    numeric_columns = results_df.select_dtypes(include=[np.number]).columns\n",
    "    results_df_numeric = results_df[['trade_time'] + list(numeric_columns)]\n",
    "    \n",
    "    # Downsample data to 1 frame per minute\n",
    "    results_df_downsampled = results_df_numeric.resample('min', on='trade_time').mean().reset_index()\n",
    "    \n",
    "    return results_df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a910753e-48df-434f-8319-ef2e887f0295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2d_ii\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def create_static_inventory_plot(results_df_downsampled):\n",
    "    \"\"\"Create a static inventory plot.\"\"\"\n",
    "    # Create figure with subplots\n",
    "    fig = make_subplots(rows=2, cols=1, subplot_titles=('ETH Inventory Evolution', 'USDT Inventory Evolution'), vertical_spacing=0.15)\n",
    "    \n",
    "    # Add ETH inventory traces\n",
    "    fig.add_trace(go.Scatter(x=results_df_downsampled['trade_time'], \n",
    "                   y=results_df_downsampled['hedge_eth_balance'], name='Hedge ETH', line=dict(color='blue')), row=1, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=results_df_downsampled['trade_time'], \n",
    "                   y=results_df_downsampled['warehouse_eth_balance'], name='Warehouse ETH', line=dict(color='orange')), row=1, col=1)\n",
    "    \n",
    "    # Add USDT inventory traces\n",
    "    fig.add_trace(go.Scatter(x=results_df_downsampled['trade_time'],  \n",
    "                    y=results_df_downsampled['hedge_usdt_balance'], name='Hedge USDT', line=dict(color='blue'), showlegend=False), row=2, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=results_df_downsampled['trade_time'], \n",
    "                    y=results_df_downsampled['warehouse_usdt_balance'], name='Warehouse USDT', line=dict(color='orange'), showlegend=False), row=2, col=1)\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(height=800, title_text=\"Inventory Evolution with Trade Flow\", hovermode=\"x unified\")\n",
    "    \n",
    "    # Update y-axis titles\n",
    "    fig.update_yaxes(title_text=\"ETH Balance\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"USDT Balance\", row=2, col=1)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c15c6bdf-b901-414f-b100-bbbcdeaa0439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2d_iii\n",
    "def add_animation_frames(fig, results_df_downsampled):\n",
    "    \"\"\"Add animation frames to inventory plot.\"\"\"\n",
    "    frames = []\n",
    "    for i in range(1, len(results_df_downsampled) + 1):\n",
    "        frame_df = results_df_downsampled.iloc[:i]\n",
    "        frames.append(go.Frame(data=[go.Scatter(x=frame_df['trade_time'], y=frame_df['hedge_eth_balance']),        # ETH Hedge\n",
    "                go.Scatter(x=frame_df['trade_time'], y=frame_df['warehouse_eth_balance']),                         # ETH Warehouse\n",
    "                go.Scatter(x=frame_df['trade_time'], y=frame_df['hedge_usdt_balance']),                            # USDT Hedge\n",
    "                go.Scatter(x=frame_df['trade_time'], y=frame_df['warehouse_usdt_balance']),],                      # USDT Warehouse\n",
    "            name=f'frame_{i}'))\n",
    "    \n",
    "    fig.frames = frames\n",
    "    \n",
    "    # Add play/pause buttons\n",
    "    fig.update_layout(updatemenus=[{\"type\": \"buttons\", \"buttons\": [{\"label\": \"Play\", \"method\": \"animate\",\n",
    "                    \"args\": [None, {\"frame\": {\"duration\": 100, \"redraw\": True}, \"fromcurrent\": True}]},\n",
    "                {\"label\": \"Pause\", \"method\": \"animate\", \"args\": [[None], {\"frame\": {\"duration\": 0, \"redraw\": False}, \"mode\": \"immediate\"}]}], \"x\": 0.1, \"y\": 0,}])\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db66f11b-8616-4303-a20f-0e9b3f07a6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating animation frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frames Progress: 100%|███████████████████████| 590/590 [00:01<00:00, 366.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization saved to Portfolio-Tracking-Visualization.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load results DF\n",
    "results = pd.read_csv('results/portfolio_tracking_results.csv')\n",
    "\n",
    "# Prep & downsample the data\n",
    "results['trade_time'] = pd.to_datetime(results['trade_time'])\n",
    "numeric_columns = results.select_dtypes(include=[float, int]).columns\n",
    "results_numeric = results[['trade_time'] + list(numeric_columns)]\n",
    "results_downsampled = results_numeric.resample('5min', on='trade_time').mean().reset_index()\n",
    "\n",
    "# Scale down USDT balance by 10x\n",
    "results_downsampled['USDT_Cum_Balance_scaled'] = results_downsampled['USDT_Cum_Balance'] / 10\n",
    "\n",
    "# Create figure with secondary y-axis\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add ETH Net Cumulative Balance to primary y-axis (left)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=results_downsampled['trade_time'],\n",
    "    y=results_downsampled['ETH_Net_Cum_Balance'],\n",
    "    name='ETH Net Cumulative Balance',\n",
    "    line=dict(color='blue')))\n",
    "\n",
    "# Add the other traces to secondary y-axis (right)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=results_downsampled['trade_time'],\n",
    "    y=results_downsampled['Portfolio_Value'],\n",
    "    name='Portfolio Value',\n",
    "    line=dict(color='green'),\n",
    "    yaxis='y2'))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=results_downsampled['trade_time'],\n",
    "    y=results_downsampled['USDT_Cum_Balance_scaled'],\n",
    "    name='USDT Cumulative Balance (scaled 1/10)',\n",
    "    line=dict(color='orange'),\n",
    "    yaxis='y2'))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=results_downsampled['trade_time'],\n",
    "    y=results_downsampled['Cum_PnL'],\n",
    "    name='Cumulative PnL',\n",
    "    line=dict(color='purple'),\n",
    "    yaxis='y2'))\n",
    "\n",
    "# Add annotation about scaling\n",
    "fig.add_annotation(\n",
    "    x=0.02,\n",
    "    y=0.95,\n",
    "    xref='paper',\n",
    "    yref='paper',\n",
    "    text=\"<b>Note:</b> USDT Balance values are scaled down by 10x\",\n",
    "    showarrow=False,\n",
    "    font=dict(size=12),\n",
    "    bgcolor=\"white\",\n",
    "    bordercolor=\"black\",\n",
    "    borderwidth=1)\n",
    "\n",
    "# Create axis objects\n",
    "fig.update_layout(\n",
    "    title='Portfolio Tracking Over Time',\n",
    "    xaxis=dict(title='Time'),\n",
    "    yaxis=dict(\n",
    "        title='ETH Net Cumulative Balance',\n",
    "        titlefont=dict(color='blue'),\n",
    "        tickfont=dict(color='blue')),\n",
    "    yaxis2=dict(\n",
    "        title='Portfolio Value, USDT Balance (scaled), & PnL',\n",
    "        titlefont=dict(color='orange'),\n",
    "        tickfont=dict(color='orange'),\n",
    "        anchor='x',\n",
    "        overlaying='y',\n",
    "        side='right'),\n",
    "    legend=dict(x=1.1, y=1.0),\n",
    "    margin=dict(l=100, r=100, t=80, b=80)  # Add margin for annotation)\n",
    "\n",
    "# Add animation frames with progress bar\n",
    "frames = []\n",
    "print(\"Generating animation frames...\")\n",
    "for i in tqdm(range(1, len(results_downsampled) + 1), desc=\"Frames Progress\"):\n",
    "    frame_df = results_downsampled.iloc[:i]\n",
    "    frames.append(go.Frame(\n",
    "        data=[\n",
    "            go.Scatter(x=frame_df['trade_time'], y=frame_df['ETH_Net_Cum_Balance']),\n",
    "            go.Scatter(x=frame_df['trade_time'], y=frame_df['Portfolio_Value'], yaxis='y2'),\n",
    "            go.Scatter(x=frame_df['trade_time'], y=frame_df['USDT_Cum_Balance_scaled'], yaxis='y2'),\n",
    "            go.Scatter(x=frame_df['trade_time'], y=frame_df['Cum_PnL'], yaxis='y2')],\n",
    "        name=f'frame_{i}'))\n",
    "\n",
    "fig.frames = frames\n",
    "\n",
    "# Add play/pause buttons\n",
    "fig.update_layout(\n",
    "    updatemenus=[{\n",
    "        \"type\": \"buttons\",\n",
    "        \"buttons\": [\n",
    "            {\n",
    "                \"label\": \"Play\",\n",
    "                \"method\": \"animate\",\n",
    "                \"args\": [None, {\"frame\": {\"duration\": 100, \"redraw\": True}, \"fromcurrent\": True}]},\n",
    "            {\n",
    "                \"label\": \"Pause\",\n",
    "                \"method\": \"animate\",\n",
    "                \"args\": [[None], {\"frame\": {\"duration\": 0, \"redraw\": False}, \"mode\": \"immediate\"}]}]}])\n",
    "\n",
    "# Save as HTML file\n",
    "fig.write_html(\"Portfolio-Tracking-Visualization.html\")\n",
    "print(\"Visualization saved to Portfolio-Tracking-Visualization.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f6b67f-22a5-480c-a077-eed760968242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
